Created by Samantha Coyle on 5/10/2018
This document contains research specific summary statements regarding my research with Mr. Greg LaKomski, and Dr. Apan Qasem of Texas State University. This investigation explores and compares runtime efficiency and resource consumption for both recursive and dynamic programming across several different programming languages that abstract widely differing architectural elements. The results of the research so far were presented at the Women in Science and Engineering (WiSE) Conference at Texas State University (March 2018), and the research is being continued.

Initial research statements to include more languages tested:
The overall runtime and resource consumption for the recursive algorithm was larger than the dynamic algorithm runtimes, due to the higher overhead with recursive calls and the allocation of memory resources for the recursive calls. Initially, this research included Perl, Python, C, and Go. In analyzing these languages utilizing the perf command line utility, we discovered that Perl, Python, and Go likely reached their physical memory limits as the recursive calls became too large around Fibonacci of 40. We can see this in the exponentially large runtimes.
The interpreted languages executed faster than the compiled languages for the dynamic algorithm. This is the opposite of what one would expect, and we believe it can be explained by the different default optimization levels of the programs, as well as potential issues with the scope of the Fibonacci numbers.
	
Focus on C++ and Python:
C++ consistently outperformed Python on task-clock time, CPU-cycles, instruction count, instructions per second, and elapsed time. When it came to speedup calculations, C++ greatly outperformed Python by at least a factor of 28 over Python for fib of 20-40, with fib of 5 for the intervals.
Regarding the memory resources, Python had significantly more page faults than C++ overall. For both the recursive algorithm, and the dynamic algorithm, C++ had around 40 page faults, whereas Python had about 800 page faults for both its recursive and dynamic algorithm for all fib numbers evaluated. As for the cache misses, Python also fared worse. Python showed exponential growth for its recursive algorithm cache misses, starting at about 300000, whereas C++ started around 15000 for its cache misses, and also depicted exponential growth. Python also had more cache misses in the dynamic algorithm with about 270000 cache misses, whereas C++ had about 7800 cache misses for the dynamic algorithm. In addition, the cache misses’ percent of all cache references decreased substantially for Python from 16 to just above 0 for fib of 20-40; this trend was similar to C++’s performance, but from a starting point of 25 down to 10. A cache miss is when the data requested for is not in the cache memory, and requires the program to fetch the data from other cache levels, or main memory. These high percentages for the cache misses as a percent of all cache references can lead to significant delays in execution time.

Inline C++ vs C++ with a focus on the recursive algorithm:
C++ remained under 1 millisecond for all Fibonacci numbers tested, but inline C++ went all the way up to 3247.92 milliseconds. C++ utilized 858,889,235,221 CPU cycles for Fibonacci of 50, whereas inline C++ only got up to 6,971,907,740 CPU cycles. Inline C++ utilized a lot more instructions than C++ did, being that the idea behind the keyword “inline” reduces the amount of function calls by replacing the function call with the contents of the function itself. Both forms of C++ had about the same number of CPUs utilized. Interestingly, inline C++ used 100% less GHz for its clock rate compared to C++ for Fibonacci of 20, but inline C++ and C++ grow to about the same clock rate after Fibonacci of 50. Initially, inline C++ had more than double the number of instructions per second than C++; however, as the Fibonacci value increased for the function parameter input, the processor speed for both equated to about the same. Both inline C++ and C++ had the same average number of page-faults, cache misses, and percent of all cache refs being cache misses. The one-minute difference between the two include C++ increasing a bit, and then gradually decreasing, while inline C++ decreases drastically, increases a bit, and then decreases at a more gradual pace.

Decorated Python vs Python with a focus on the recursive algorithm:
Python took longer for its task clock rates than that of Decorated Python with Fib of 40 being 91871.376 milliseconds for Python, and about 36 milliseconds for Decorated Python. Decorated Python used far fewer CPU cycles with its highest around 61,000,000, and Python using around 132,298,225,415 cycles for Fib of 40. Decorated Python also used far fewer instructions, and a smaller clock rate. Decorated Python did use more instructions, having around 2,500,000,000,000 instructions, and Python using around 28,000,000. With regard to cache, Decorated Python was costlier having more page faults. However, it significantly improved cache misses from almost 42,500,000 cache misses with Python to almost 290,000 cache misses with Decorated Python. It’s interesting to note that Python had a continual decline down to almost 0% for its cache misses as a percent of all cache references; whereas Decorated Python remained constant at 15% for Fibonacci values of 20 through 100.

C++ vs Decorated Python with a focus on the recursive algorithm:
C++ was faster than Decorated Python with a speedup of almost 30 for Fibonacci of 20, but the two switched places after Fibonacci of 30, with Decorated Python ending Fibonacci of 40 almost 90 times faster than C++. Decorated Python had fewer CPU cycles at 60,976,899.33 cycles, with C++ using 858,889,235,221. Decorated Python also outperformed C++ in regard to instruction count, having 28,075,491.67 instructions, and C++ using 6,169,788,902. Both used about 0.9 CPUs, but C++ used 2.156 GHz, and Decorated Python only used 1.666 GHz for Fibonacci of 40. On the other hand, Decorated Python had at least 810 page faults for every Fibonacci value tested, whereas C++ had at most 41 page faults. Decorated Python was also costlier for cache misses. However, C++’s cache misses as a percent of all cache references decreased from about 25% to 10% and Decorated Python maintained 15% for every trial.

Interesting:
C was very close after fib of 30 on number of CPUs utilized vs Python
C utilized 4 times the calculated time than Python did (time sum including user and system time).

Summary Statements:
C++ outperformed Python in almost every regard.
Python was less efficient with its memory allocation, resulting in many more page faults and cache misses.
With many recursive calls, C++ would be the better choice with a faster execution time. However, inline C++ used far fewer CPU cycles, with hundreds of millions more instructions than C++ did. When it comes down to the cache, there is little difference between inline C++ and C++.
Having a decorated Python function takes a bit longer to execute, but it significantly improved the number of CPU cycles utilized, the number of instructions executed, and far fewer cache misses. Decorated Python does take a hit with more page faults and a constant of about 15% of all cache references being cache misses.
Decorated Python outperformed C++ in regard to execution time and speedup, CPU cycles, clock rate, and instruction count. However, Decorated Python was far costlier in terms of page faults, and cache misses.

Possible reasons why the data is what it is:
Python utilizes a private heap with Python objects for its memory allocation, whereas C++ uses a stack. Stack memory allocation is much more efficient with because of the trivial allocation and deallocation of memory. Heaps have much more complicated bookkeeping of the allocating and freeing of memory. The inefficiencies in memory can have substantial ramifications on the execution times of Python, as seen in the data.
Decorated Python created a way to decorate the Fibonacci function to almost make a dynamic algorithm out of the recursive algorithm, by saving some of the already calculated values.
Perf’s calculations are not always perfect being that it is sample based. This means that we may not get all of the ups and downs of the data since it won’t look at the entire length of execution for the code.

		

